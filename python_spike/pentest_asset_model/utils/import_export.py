"""Import and export utilities for asset data"""

import json
import csv
from typing import Dict, List, Any
from pathlib import Path

from pentest_asset_model.models.base import Asset
from pentest_asset_model.services.repository import AssetRepository


class ImportExport:
    """Utilities for importing and exporting asset data"""

    @staticmethod
    def export_to_json(repository: AssetRepository, file_path: str, pretty: bool = True):
        """
        Export repository to JSON file.

        Args:
            repository: AssetRepository to export
            file_path: Destination file path
            pretty: Pretty-print JSON (default True)
        """
        data = {
            "metadata": {
                "version": "1.0",
                "asset_count": repository.count_assets(),
                "export_timestamp": ImportExport._get_timestamp()
            },
            "statistics": repository.get_statistics(),
            "assets": [asset.to_dict() for asset in repository.get_all_assets()]
        }

        with open(file_path, 'w') as f:
            if pretty:
                json.dump(data, f, indent=2)
            else:
                json.dump(data, f)

    @staticmethod
    def export_to_csv(repository: AssetRepository, directory: str):
        """
        Export repository to CSV files (one per asset type).

        Args:
            repository: AssetRepository to export
            directory: Destination directory for CSV files
        """
        Path(directory).mkdir(parents=True, exist_ok=True)

        # Group assets by type
        by_type = {}
        for asset in repository.get_all_assets():
            asset_type = asset.asset_type.value
            if asset_type not in by_type:
                by_type[asset_type] = []
            by_type[asset_type].append(asset)

        # Export each type to separate CSV
        for asset_type, assets in by_type.items():
            file_path = Path(directory) / f"{asset_type}.csv"
            ImportExport._export_assets_to_csv(assets, str(file_path))

    @staticmethod
    def _export_assets_to_csv(assets: List[Asset], file_path: str):
        """Export list of assets to CSV file"""
        if not assets:
            return

        # Collect all property keys
        property_keys = set()
        for asset in assets:
            property_keys.update(asset.properties.keys())

        # Define CSV columns
        columns = [
            "id", "name", "asset_type", "lifecycle_state",
            "discovered_at", "discovery_method", "confidence", "risk_score"
        ] + sorted(property_keys)

        with open(file_path, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=columns)
            writer.writeheader()

            for asset in assets:
                row = {
                    "id": asset.id,
                    "name": asset.name,
                    "asset_type": asset.asset_type.value,
                    "lifecycle_state": asset.lifecycle_state.value,
                    "discovered_at": asset.discovered_at.isoformat(),
                    "discovery_method": asset.discovery_method.value,
                    "confidence": asset.confidence,
                    "risk_score": asset.risk_score
                }

                # Add properties
                for key in property_keys:
                    value = asset.get_property(key)
                    # Convert complex types to string
                    if isinstance(value, (list, dict)):
                        row[key] = json.dumps(value)
                    else:
                        row[key] = value

                writer.writerow(row)

    @staticmethod
    def export_relationships_to_csv(repository: AssetRepository, file_path: str):
        """
        Export all relationships to CSV file.

        Args:
            repository: AssetRepository to export
            file_path: Destination file path
        """
        relationships = []

        for asset in repository.get_all_assets():
            for rel_type, rels in asset.relationships.items():
                for rel in rels:
                    relationships.append({
                        "source_id": asset.id,
                        "source_name": asset.name,
                        "source_type": asset.asset_type.value,
                        "relationship_type": rel_type,
                        "target_id": rel.target_id,
                        "confidence": rel.confidence,
                        "discovered_at": rel.discovered_at.isoformat(),
                        "validated": rel.validated
                    })

        if not relationships:
            return

        columns = [
            "source_id", "source_name", "source_type",
            "relationship_type", "target_id",
            "confidence", "discovered_at", "validated"
        ]

        with open(file_path, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=columns)
            writer.writeheader()
            writer.writerows(relationships)

    @staticmethod
    def export_to_graphml(repository: AssetRepository, file_path: str):
        """
        Export repository to GraphML format for visualization.

        Args:
            repository: AssetRepository to export
            file_path: Destination file path
        """
        graphml = ['<?xml version="1.0" encoding="UTF-8"?>']
        graphml.append('<graphml xmlns="http://graphml.graphdrawing.org/xmlns">')
        graphml.append('  <key id="name" for="node" attr.name="name" attr.type="string"/>')
        graphml.append('  <key id="type" for="node" attr.name="type" attr.type="string"/>')
        graphml.append('  <key id="state" for="node" attr.name="state" attr.type="string"/>')
        graphml.append('  <key id="risk" for="node" attr.name="risk_score" attr.type="double"/>')
        graphml.append('  <key id="reltype" for="edge" attr.name="relationship_type" attr.type="string"/>')
        graphml.append('  <graph id="G" edgedefault="directed">')

        # Add nodes (assets)
        for asset in repository.get_all_assets():
            graphml.append(f'    <node id="{asset.id}">')
            graphml.append(f'      <data key="name">{asset.name}</data>')
            graphml.append(f'      <data key="type">{asset.asset_type.value}</data>')
            graphml.append(f'      <data key="state">{asset.lifecycle_state.value}</data>')
            graphml.append(f'      <data key="risk">{asset.risk_score}</data>')
            graphml.append('    </node>')

        # Add edges (relationships)
        edge_id = 0
        for asset in repository.get_all_assets():
            for rel_type, rels in asset.relationships.items():
                for rel in rels:
                    graphml.append(f'    <edge id="e{edge_id}" source="{asset.id}" target="{rel.target_id}">')
                    graphml.append(f'      <data key="reltype">{rel_type}</data>')
                    graphml.append('    </edge>')
                    edge_id += 1

        graphml.append('  </graph>')
        graphml.append('</graphml>')

        with open(file_path, 'w') as f:
            f.write('\n'.join(graphml))

    @staticmethod
    def export_summary_report(repository: AssetRepository, file_path: str):
        """
        Export human-readable summary report.

        Args:
            repository: AssetRepository to export
            file_path: Destination file path
        """
        from pentest_asset_model.utils import RiskScorer

        lines = []
        lines.append("=" * 80)
        lines.append("PENETRATION TEST ASSET INVENTORY REPORT")
        lines.append("=" * 80)
        lines.append("")

        # Summary statistics
        stats = repository.get_statistics()
        lines.append("SUMMARY STATISTICS")
        lines.append("-" * 80)
        lines.append(f"Total Assets: {stats['total_assets']}")
        lines.append("")

        lines.append("Assets by Type:")
        for asset_type, count in sorted(stats['by_type'].items()):
            lines.append(f"  - {asset_type}: {count}")
        lines.append("")

        lines.append("Assets by Lifecycle State:")
        for state, count in sorted(stats['by_state'].items()):
            lines.append(f"  - {state}: {count}")
        lines.append("")

        # Risk profile
        risk_profile = RiskScorer.calculate_repository_risk_profile(repository)
        lines.append("RISK PROFILE")
        lines.append("-" * 80)
        lines.append(f"Average Risk Score: {risk_profile['average_risk']:.2f}/10")
        lines.append(f"Maximum Risk Score: {risk_profile['max_risk']:.2f}/10")
        lines.append(f"High Risk Assets (>=7.0): {risk_profile['high_risk_count']}")
        lines.append(f"Medium Risk Assets (4.0-6.9): {risk_profile['medium_risk_count']}")
        lines.append(f"Low Risk Assets (<4.0): {risk_profile['low_risk_count']}")
        lines.append("")

        # High-risk assets
        high_risk = [a for a in repository.get_all_assets() if a.risk_score >= 7.0]
        if high_risk:
            lines.append("HIGH-RISK ASSETS")
            lines.append("-" * 80)
            for asset in sorted(high_risk, key=lambda a: a.risk_score, reverse=True):
                lines.append(f"{asset.name} ({asset.asset_type.value})")
                lines.append(f"  Risk Score: {asset.risk_score:.2f}/10")
                lines.append(f"  State: {asset.lifecycle_state.value}")
                lines.append("")

        with open(file_path, 'w') as f:
            f.write('\n'.join(lines))

    @staticmethod
    def _get_timestamp() -> str:
        """Get current timestamp in ISO format"""
        from datetime import datetime
        return datetime.now().isoformat()
